# -*- coding: utf-8 -*-
"""pretrained_model_example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x2t3H23Thceo0A4Yn--N_1qN0WxUcEuG
"""

!pip install transformers librosa numpy torchaudio

import numpy as np
import librosa
import torch
from transformers import Wav2Vec2Processor, Wav2Vec2Model

# Function to generate a sine wave
def generate_sine_wave(frequency, sample_rate, duration):
    t = np.linspace(0, duration, int(sample_rate * duration), False)
    sine_wave = np.sin(2 * np.pi * frequency * t)
    return sine_wave

# Generate a 1-second sine wave at 440 Hz (A4 note)
sample_rate = 16000  # Sample rate used by the model
sine_wave = generate_sine_wave(440, sample_rate, 1)

# Ensure the sine wave is in the correct format (float32)
sine_wave = sine_wave.astype(np.float32)

# Load the processor and model
processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")
model = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-base-960h")

# Process the audio to model input format
input_values = processor(sine_wave, return_tensors="pt", padding="longest", sampling_rate=sample_rate).input_values

# Extract features
with torch.no_grad():
    features = model(input_values).last_hidden_state

print("Feature extraction complete.")
print(f"Shape of extracted features: {features.shape}")

